{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT from scratch\n",
    "\n",
    "We build a GPT model from scratch. We use the AG_NEWS dataset that is built-in in torchtext and use some of the tokenization tools from torchtext. A huggingface pipeline might have taken care of all of the pre-training steps but we wanted to get a more detailed understanding of the entire pipeline. \n",
    "\n",
    "We train a small-ish model for 5 epochs and test it in two ways. First, we look at its predictions on the first test batch to see if the predictions are plausible. Secondly, we investigate the test loss on a random network vs. our trained network. \n",
    "\n",
    "Our model is not perfect but we think it is sufficiently different from random chance that we can say it has learned something and our pipeline is functional. Our goal was not to reproduce or beat the state of the art but just to built a working pipeline so we stop there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "7600\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_test = torchtext.datasets.AG_NEWS()\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = torchtext.datasets.AG_NEWS(split='train')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        text = \"[SOS] \" + text + \" [EOS]\"\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), min_freq=2,\n",
    "                                  specials=[\"[PAD]\", \"[UNK]\", \"[SOS]\", \"[EOS]\"])\n",
    "vocab.set_default_index(vocab[\"[UNK]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.datasets_utils._RawTextIterableDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53132\n"
     ]
    }
   ],
   "source": [
    "#vocab(['here', 'is', 'an', 'example'])\n",
    "vocab([\"the\"])\n",
    "full_vocab = vocab.vocab.get_stoi().keys()\n",
    "print(len(full_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([    8,    54,  6619, 47693,  2645,    12,     1,     6,    50,\n",
      "          72,   749, 10620,     4,  4310,     9,   227,    35,  1889,\n",
      "       13154,     6,    12,     1,     6,    54,  1363,     5,    52,\n",
      "        7959,     9,   227,    66,    12,  6424,     6,    13,     1,\n",
      "         234,     6,    50,     5, 13154,    40, 15493,    12,   320,\n",
      "           4,    12,  1921, 30443,     6,    54,    40,   799,    16,\n",
      "           1,     6,    13,    40,  2492,   172,     5,   441,    11,\n",
      "        9521,     6,     5,    74,   106,    10,  8111,    40,  2492,\n",
      "          29,     5,  9521,     4,     7,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0]), array([   54,  6619, 47693,  2645,    12,     1,     6,    50,    72,\n",
      "         749, 10620,     4,  4310,     9,   227,    35,  1889, 13154,\n",
      "           6,    12,     1,     6,    54,  1363,     5,    52,  7959,\n",
      "           9,   227,    66,    12,  6424,     6,    13,     1,   234,\n",
      "           6,    50,     5, 13154,    40, 15493,    12,   320,     4,\n",
      "          12,  1921, 30443,     6,    54,    40,   799,    16,     1,\n",
      "           6,    13,    40,  2492,   172,     5,   441,    11,  9521,\n",
      "           6,     5,    74,   106,    10,  8111,    40,  2492,    29,\n",
      "           5,  9521,     4,     7,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           0]), tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True]))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "# copied from tutorial, added padding\n",
    "def text_pipeline(x, max_len):\n",
    "    x = \"[SOS] \" + x + \" [EOS]\"\n",
    "    vocab_list = np.array(vocab(tokenizer(x)))[:max_len]\n",
    "    k = len(vocab_list)\n",
    "    missing_len = max_len - k\n",
    "    missing_list = missing_len * vocab([\"[PAD]\"])\n",
    "    # true labels\n",
    "    labels = np.concatenate([copy.deepcopy(vocab_list), missing_list])\n",
    "    labels = np.concatenate([labels[1:], vocab([\"[PAD]\"])])\n",
    "    # save vector indicating paddings\n",
    "    paddings = torch.cat([torch.zeros((k,)), torch.ones((len(missing_list),))])\n",
    "    paddings = paddings.bool()\n",
    "    \n",
    "    return(np.concatenate([vocab_list, missing_list]), labels, paddings)\n",
    "\n",
    "print(text_pipeline('He married Mabel Scott in 1890, but they soon separated. Unable to get an English divorce, in 1900, he became the first celebrity to get one in Nevada, and remarried there, but the divorce was invalid in England. In June 1901, he was arrested for bigamy, and was convicted before the House of Lords, the last time a peer was convicted by the Lords.', 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# copied from tutorial, removed offsets\n",
    "from torch.utils.data import DataLoader\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, padding_list = [], [], []\n",
    "    for _, text in batch:\n",
    "        input_, label_, padding_ = text_pipeline(text, max_len=100)\n",
    "        text_list.append(torch.tensor(input_, dtype=torch.int64))\n",
    "        label_list.append(label_)\n",
    "        padding_list.append(torch.tensor(padding_))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = torch.cat(text_list).view(len(label_list), -1)\n",
    "    padding_list = torch.cat(padding_list).view(len(label_list), -1)\n",
    "    return text_list.to(DEVICE), label_list.to(DEVICE), padding_list\n",
    "\n",
    "train_iter = dataset_train\n",
    "BATCH_SIZE = 32\n",
    "dataloader = DataLoader(list(train_iter), batch_size=BATCH_SIZE, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### build classifier transformer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyGPT(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, heads, seq_length, vocab_size, depth=5, num_classes=2, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_emb = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_emb = nn.Embedding(seq_length, embedding_dim)\n",
    "        self.num_heads = heads\n",
    "        indices = torch.triu_indices(seq_length, seq_length, offset=1)\n",
    "        self.attn_mask = torch.zeros((seq_length, seq_length))\n",
    "        self.attn_mask[indices[0], indices[1]] = float(\"-inf\")\n",
    "        #self.attn_mask[indices[0], indices[1]] = False\n",
    "        self.attn_mask = self.attn_mask.to(device)\n",
    "        self.device = device\n",
    "\n",
    "        # sequence of transformers\n",
    "        self.tblocks = []\n",
    "        for i in range(depth):\n",
    "            self.tblocks.append(nn.TransformerDecoderLayer(d_model=embedding_dim,\n",
    "                                                            nhead=self.num_heads, \n",
    "                                                            batch_first=True, \n",
    "                                                            norm_first=True,\n",
    "                                                            dropout=0.1).to(device))\n",
    "        #self.tblocks = nn.Sequential(*tblocks)\n",
    "        \n",
    "        # final linear layer\n",
    "        self.last_linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, paddings, pos_ids=None):\n",
    "        # generate positional embeddings\n",
    "        if pos_ids is None:\n",
    "            pos_ids = torch.arange(0, self.seq_length).unsqueeze(0).to(self.device)\n",
    "        # generate full embeddings\n",
    "        tokens = self.token_emb(x) + self.pos_emb(pos_ids)\n",
    "        batch_size, token_size, embed_size = tokens.size()\n",
    "\n",
    "        # apply all transformer blocks\n",
    "        x = tokens.to(self.device)\n",
    "        for block in self.tblocks:\n",
    "            x = block(x, memory=x, tgt_mask=self.attn_mask, tgt_key_padding_mask=paddings)\n",
    "\n",
    "        # predict next word with last_linear\n",
    "        out = self.last_linear(x)\n",
    "        # change order because we have batch_first=True\n",
    "        out = out.transpose(2, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-mini: n_layer=6, n_head=6, n_embd=192\n",
    "# gpt-micro: n_layer=4, n_head=4, n_embd=128\n",
    "# gpt-nano: n_layer=3, n_head=3, n_embd=48\n",
    "# gpt-mini2: n_layers=6, n_head=16, n_embd=128\n",
    "# gpt-mini3: n_layers=10, n_head=32, n_embd=256\n",
    "\n",
    "\n",
    "EMBED_DIM = 256\n",
    "NUM_HEADS = 32\n",
    "NUM_LAYERS = 10\n",
    "SEQ_LENGTH = 100\n",
    "VOCAB_SIZE = len(full_vocab)\n",
    "\n",
    "my_gpt = MyGPT(embedding_dim=EMBED_DIM, \n",
    "               heads=NUM_HEADS, \n",
    "               seq_length=SEQ_LENGTH,\n",
    "               vocab_size=VOCAB_SIZE,\n",
    "               depth=NUM_LAYERS).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(my_gpt.parameters(), lr=3e-4, betas=(0.9, 0.95))\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fb8b28e98644b08fc1553a7ea501f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2131/241580691.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padding_list.append(torch.tensor(padding_))\n",
      "/tmp/ipykernel_2131/241580691.py:13: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  label_list = torch.tensor(label_list, dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  11376.841796875\n",
      "epoch:  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71493aaec9c544beb93e6c74541f62ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  10240.888671875\n",
      "epoch:  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255136b7d1cb4a74bfbae923c0434818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  9901.4970703125\n",
      "epoch:  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008dbd5c603a4aa1ac69d6fb05f05761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  9647.5439453125\n",
      "epoch:  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c2a2069afe48eaae473b88bdf789ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  9417.919921875\n",
      "epoch:  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafb36913f6d4625ab873e69b44aba9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  9207.0107421875\n",
      "epoch:  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf24cc4f5d2451f99dc4464aa6b505b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  9049.6396484375\n",
      "epoch:  7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fd292463674fcb947cad1531fe1590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8976.3525390625\n",
      "epoch:  8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aefd2e4450e41e582006ce8ecb0df80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8935.974609375\n",
      "epoch:  9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6705344de6bd4b0aba2c7715c6de8ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8899.72265625\n",
      "epoch:  10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2224d9c84cbf46b7ba98d6a4e4e53995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8866.0166015625\n",
      "epoch:  11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d80a9cd7d345b29d68f70de3e5bbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8833.0810546875\n",
      "epoch:  12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b79bef316854beab7c53c1762679f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8798.845703125\n",
      "epoch:  13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a3d08931d245f28d3a3aaa519c910c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8765.5078125\n",
      "epoch:  14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454641ac8b9e4a0e8421237e58c3eca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8732.435546875\n",
      "epoch:  15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5102ffe2d1c44e258026fd8563360cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8700.685546875\n",
      "epoch:  16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cba1a6e35e4136a2c050f1a3353247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8669.4267578125\n",
      "epoch:  17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c33baeec934474bb42faa985c60a015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8640.04296875\n",
      "epoch:  18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859de750d78a4086bc9be2b9d78c189f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8611.9853515625\n",
      "epoch:  19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0634a7dcb1045159bb8b33b433c92f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8584.830078125\n",
      "epoch:  20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8bf7b00f3a487287ac299bcbc72855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8558.9833984375\n",
      "epoch:  21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58130b2a26054a6fb84a3cef598bb378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8533.1279296875\n",
      "epoch:  22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b72f7a8fd2c4d79ac801d0302dc7f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8509.4775390625\n",
      "epoch:  23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193495e1c3e04c67beba9cd59f709555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8485.9033203125\n",
      "epoch:  24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3603dcb4413e4950a4ee607630eedbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8464.76953125\n",
      "epoch:  25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dea0c9b0bae4d2e93b7c9fe89300b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8444.51953125\n",
      "epoch:  26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713491216f87460db29224e3fb10c9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8423.86328125\n",
      "epoch:  27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b4622d5efc4e88b90e7a8098e66205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8404.6357421875\n",
      "epoch:  28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632ede2a49a442f5a3aa223612102fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8386.591796875\n",
      "epoch:  29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb3ebea8aad409caab60a5749aff455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8369.9072265625\n",
      "epoch:  30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d0c53442fc4e668177be4feab05f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8353.375\n",
      "epoch:  31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b608a0c8c7648e594303ff7b18a19e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8336.498046875\n",
      "epoch:  32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42441a5fe2af4747a66ad6a8920c9d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8320.3720703125\n",
      "epoch:  33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81307bf8ffc4dc78ac482f4af7bc00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8305.62109375\n",
      "epoch:  34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7eab9d7ebd24b499558470bb986c456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8291.24609375\n",
      "epoch:  35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710658e93acf4ac6873fe1e8577d71ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8277.046875\n",
      "epoch:  36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3195a4a30cc9403e992817159f61befc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8263.447265625\n",
      "epoch:  37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d01786fde7744a794088c3f131e1663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8251.0830078125\n",
      "epoch:  38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff72052f49e4ce18ba06eb2b721adb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8238.6923828125\n",
      "epoch:  39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d39cdce91040d58150e8be10774238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8226.5009765625\n",
      "epoch:  40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3bc2a9666546d1a2037d737bf49835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8214.6455078125\n",
      "epoch:  41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e79a444fda460b85cd6444c8994857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8204.2275390625\n",
      "epoch:  42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31601f724c884055adc4f73e3f48122a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8194.5322265625\n",
      "epoch:  43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d9bdc46ed544b69ceeceafc7fa1e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8183.908203125\n",
      "epoch:  44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a60d3f7365a4763873ccfd5ee60a0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8174.2109375\n",
      "epoch:  45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dccfe454b3e4fd58afa52b961f50f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8165.64306640625\n",
      "epoch:  46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5e471721f148fca8a3a918f6fadf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8154.7509765625\n",
      "epoch:  47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b531a69f0f4c8aa870a0af7be2d270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8147.16064453125\n",
      "epoch:  48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1393ec85584b7999f61a70b2ef44bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8137.9892578125\n",
      "epoch:  49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee61ed7e59545a8b9cbc6cc25d40d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_loss:  8130.02978515625\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch: \", epoch)\n",
    "    training_loss = 0\n",
    "    for i, (x, y, paddings) in tqdm(enumerate(dataloader), total=len(dataset_train)//BATCH_SIZE):\n",
    "\n",
    "        #if i > 50: break\n",
    "        optimizer.zero_grad()\n",
    "        x,y, paddings = x.to(DEVICE), y.to(DEVICE), paddings.to(DEVICE)\n",
    "\n",
    "        out = my_gpt(x, paddings)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        training_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"training_loss: \", training_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights\n",
    "PATH = \"my_gpt_mini3_it50.pth\" #mini3_it50 has training loss of 8130\n",
    "#torch.save(my_gpt.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "testloader = DataLoader(list(dataset_test), batch_size=BATCH_SIZE, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d68b0cc1be6404da5823e4ea3fcc121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19920/241580691.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padding_list.append(torch.tensor(padding_))\n",
      "/tmp/ipykernel_19920/241580691.py:13: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
      "/tmp/ipykernel_19920/241580691.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  label_list = torch.tensor(label_list, dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from random network: 5779.365\n"
     ]
    }
   ],
   "source": [
    "### test the model on a random init version of the network\n",
    "random_network = MyGPT(embedding_dim=EMBED_DIM, \n",
    "               heads=NUM_HEADS, \n",
    "               seq_length=SEQ_LENGTH,\n",
    "               vocab_size=VOCAB_SIZE,\n",
    "               depth=NUM_LAYERS).to(DEVICE)\n",
    "\n",
    "random_network.eval()\n",
    "\n",
    "random_test_loss = 0\n",
    "for i, (x, y, paddings) in tqdm(enumerate(testloader), total=len(dataset_test)//BATCH_SIZE):\n",
    "\n",
    "        #if i > 50: break\n",
    "        x,y, paddings = x.to(DEVICE), y.to(DEVICE), paddings.to(DEVICE)\n",
    "\n",
    "        out = random_network(x, paddings)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        random_test_loss += loss.item()\n",
    "        \n",
    "print(\"test loss from random network: {:.03f}\".format(random_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyGPT(\n",
       "  (token_emb): Embedding(53132, 256)\n",
       "  (pos_emb): Embedding(100, 256)\n",
       "  (last_linear): Linear(in_features=256, out_features=53132, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load model\n",
    "\n",
    "trained_model = MyGPT(embedding_dim=EMBED_DIM, \n",
    "               heads=NUM_HEADS, \n",
    "               seq_length=SEQ_LENGTH,\n",
    "               vocab_size=VOCAB_SIZE,\n",
    "               depth=NUM_LAYERS).to(DEVICE)\n",
    "\n",
    "trained_model.load_state_dict(torch.load(PATH))\n",
    "trained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef675afcb4074035b4b45cb5d9497125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19920/241580691.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padding_list.append(torch.tensor(padding_))\n",
      "/tmp/ipykernel_19920/241580691.py:13: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  label_list = torch.tensor(label_list, dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from trained network: 1472.208\n"
     ]
    }
   ],
   "source": [
    "### test model on our trained model \n",
    "trained_model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "for i, (x, y, paddings) in tqdm(enumerate(testloader), total=len(dataset_test)//BATCH_SIZE):\n",
    "\n",
    "        #if i > 50: break\n",
    "        optimizer.zero_grad()\n",
    "        x,y, paddings = x.to(DEVICE), y.to(DEVICE), paddings.to(DEVICE)\n",
    "\n",
    "        out = trained_model(x, paddings)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "print(\"test loss from trained network: {:.03f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate words with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, context, paddings, ntok=20, topk=5):\n",
    "    generation_start = torch.where(context == 0)[1][0] # -1\n",
    "    for i in range(ntok):\n",
    "        # predict logits for next word\n",
    "        out = model(context, paddings)\n",
    "        # select the right dimension \n",
    "        logits = out[:,:,generation_start-1]\n",
    "        # remove all but the top k indices\n",
    "        indices_to_remove = logits < min(torch.topk(logits, topk)[0][0])\n",
    "        logits[indices_to_remove] = float(\"-inf\")\n",
    "        # draw one sample from the remaining k indices weighted by their probabilities\n",
    "        next_tok = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).squeeze(1)\n",
    "        # add context to previous context\n",
    "        context[:, generation_start] = next_tok.unsqueeze(-1)\n",
    "        paddings[:, generation_start] = False\n",
    "        generation_start += 1\n",
    "        \n",
    "    return(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19920/3598451906.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_context, test_padding = torch.tensor(test_context).to(DEVICE).view(1, -1), torch.tensor(test_padding).bool().to(DEVICE).view(1, -1)\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"He married Mabel Scott in 1890, but they soon separated. \\\n",
    "Unable to get an English divorce, in 1900, he became the\"\n",
    "\"\"\" the first celebrity to get one in Nevada, \\\n",
    "and remarried there, but the divorce was invalid in England. In June 1901, he was arrested for bigamy, \\\n",
    "and was convicted before the House of Lords, the last time a peer was convicted by the Lords.\"\n",
    "\"\"\"\n",
    "test_context, _, test_padding = text_pipeline(test_sentence, max_len=100)\n",
    "test_context, test_padding = torch.tensor(test_context).to(DEVICE).view(1, -1), torch.tensor(test_padding).bool().to(DEVICE).view(1, -1)\n",
    "test_context[test_context == 7] = 0\n",
    "test_padding[test_context == 7] = True\n",
    "out = generate(my_gpt, test_context, test_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab_itos = vocab.vocab.get_itos()\n",
    "def detokenize(list_of_idxs):\n",
    "    return([full_vocab_itos[i] for i in list_of_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [sos] he married mabel scott in [UNK] , but they soon separated . unable to get an english divorce , in [UNK] , he became the eight-game progress ce-ata simao ferentz hours dailies hold koch convinces depression objected line\\cinema colgate airshow mohawk colombia bizpile flees mathis [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "list_of_strings_out = detokenize(out[0].cpu().numpy())\n",
    "s=\"\"\n",
    "for x in list_of_strings_out:\n",
    "    s += \" \"+ x\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'company oil oil new ? . oil iraq its inc oil s reuters iraq reuters t company oil t its '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"company oil oil new ? . oil iraq its inc oil s reuters iraq reuters t company oil t its \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_sentence(model, text_input, padding, ntok=20, begin_padding=20):\n",
    "    # overwrite the padding such that the model starts to predict after the first X words\n",
    "    print(\"text_input: \", \" \".join(detokenize(text_input)), \"\\n\")\n",
    "    print(\"text_input cut off: \", \" \".join(detokenize(text_input[:begin_padding])), \"\\n\")\n",
    "    padding[begin_padding:] = True\n",
    "    text_input[begin_padding:] = 0\n",
    "    test_context, test_padding = torch.tensor(text_input).to(DEVICE).view(1, -1), torch.tensor(padding).bool().to(DEVICE).view(1, -1)\n",
    "    \n",
    "    out = generate(model, test_context, test_padding)\n",
    "    \n",
    "    list_of_strings_out = detokenize(out[0].cpu().numpy())\n",
    "    s=\" \".join(list_of_strings_out)\n",
    "    print(\"s: \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j:  0\n",
      "text_input:  [sos] fears for t n pension after talks unions representing workers at turner newall say they are ' disappointed ' after talks with stricken parent firm federal mogul . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] fears for t n pension after talks unions representing workers at turner newall say they are ' disappointed ' \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19920/241580691.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padding_list.append(torch.tensor(padding_))\n",
      "/tmp/ipykernel_19920/241580691.py:13: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
      "/tmp/ipykernel_19920/2419959569.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_context, test_padding = torch.tensor(text_input).to(DEVICE).view(1, -1), torch.tensor(padding).bool().to(DEVICE).view(1, -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:  [sos] fears for t n pension after talks unions representing workers at turner newall say they are ' disappointed ' re to continue to make /b&gt it in the two countries which would /b&gt it to have to have to [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  1\n",
      "text_input:  [sos] the race is on second private team sets launch date for human spaceflight ( space . com ) space . com - toronto , canada -- a [UNK] of rocketeers competing for the #36 10 million ansari x prize , a contest [UNK] funded suborbital space flight , has officially announced the [UNK] date for its manned rocket . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] the race is on second private team sets launch date for human spaceflight ( space . com ) space \n",
      "\n",
      "s:  [sos] the race is on second private team sets launch date for human spaceflight ( space . com ) space which /b&gt which /b&gt thursday to new t have signed an end of /b&gt begin /b&gt in addition to have [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  2\n",
      "text_input:  [sos] ky . company wins grant to study peptides ( ap ) ap - a company founded by a chemistry researcher at the university of louisville won a grant to develop a method of producing better peptides , which are short chains of amino acids , the building blocks of proteins . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] ky . company wins grant to study peptides ( ap ) ap - a company founded by a chemistry \n",
      "\n",
      "s:  [sos] ky . company wins grant to study peptides ( ap ) ap - a company founded by a chemistry profile , they will begin to have to an end of its popular it to begin to the [UNK] of [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  3\n",
      "text_input:  [sos] prediction unit helps forecast wildfires ( ap ) ap - it ' s barely dawn when mike fitzpatrick starts his shift with a blur of colorful maps , figures and endless charts , but already he knows what the day will bring . lightning will strike in places he expects . winds will pick up , moist places will dry and flames will roar . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] prediction unit helps forecast wildfires ( ap ) ap - it ' s barely dawn when mike fitzpatrick starts \n",
      "\n",
      "s:  [sos] prediction unit helps forecast wildfires ( ap ) ap - it ' s barely dawn when mike fitzpatrick starts since thursday to which it to continue to the explorer over new thursday to its /b&gt it to more of [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  4\n",
      "text_input:  [sos] calif . aims to limit [UNK] smog ( ap ) ap - southern california ' s [UNK] agency went after emissions of the bovine variety friday , adopting the nation ' s first rules to reduce air pollution from dairy cow manure . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] calif . aims to limit [UNK] smog ( ap ) ap - southern california ' s [UNK] agency went \n",
      "\n",
      "s:  [sos] calif . aims to limit [UNK] smog ( ap ) ap - southern california ' s [UNK] agency went [UNK] to new law which /b&gt which would /b&gt it /b&gt thursday night , they can have to play , [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  5\n",
      "text_input:  [sos] open letter against british copyright [UNK] in schools the british department for education and skills ( [UNK] ) recently launched a music manifesto campaign , with the [UNK] intention of educating the next generation of british musicians . unfortunately , they also teamed up with the music industry ( emi , and various artists ) to make this popular . emi has apparently negotiated their end well , so that children in our schools will now be [UNK] about the [UNK] of downloading music . the ignorance and [UNK] of this got to me a little , so i \n",
      "\n",
      "text_input cut off:  [sos] open letter against british copyright [UNK] in schools the british department for education and skills ( [UNK] ) recently \n",
      "\n",
      "s:  [sos] open letter against british copyright [UNK] in schools the british department for education and skills ( [UNK] ) recently signed an end of the first european union to /b&gt the past to press conference in october in southern russia [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  6\n",
      "text_input:  [sos] [UNK] the war on terrorism [UNK] jaschan , self-confessed author of the netsky and sasser viruses , [UNK] for 70 percent of virus infections in 2004 , according to a [UNK] roundup published wednesday by antivirus company sophos . \\\\the 18-year-old jaschan was taken into custody in germany in may by police [UNK] he had admitted programming both the netsky and sasser worms , [UNK] at microsoft confirmed . ( a microsoft antivirus reward program led to [UNK] ' s arrest . ) during the five months preceding jaschan ' s capture , [UNK] at least 25 variants of \n",
      "\n",
      "text_input cut off:  [sos] [UNK] the war on terrorism [UNK] jaschan , self-confessed author of the netsky and sasser viruses , [UNK] for \n",
      "\n",
      "s:  [sos] [UNK] the war on terrorism [UNK] jaschan , self-confessed author of the netsky and sasser viruses , [UNK] for /b&gt thursday to its /b&gt it has taken it will not /b&gt when it /b&gt 2005 to boost the two [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  7\n",
      "text_input:  [sos] [UNK] [UNK] , [UNK] , key distribution , and bloom filters [UNK] and bloom filters have a lot of interesting properties for [UNK] and whitelist distribution . \\\\i think we can go one level higher though and include [UNK] [UNK] distribution in the [UNK] file for simple [UNK] based [UNK] . \\\\what if we used [UNK] and included the [UNK] key fingerprint ( s ) for identities ? \\this could mean a lot . you include the [UNK] key fingerprints within the [UNK] of your direct friends and then include a bloom filter of the [UNK] [UNK] of your \n",
      "\n",
      "text_input cut off:  [sos] [UNK] [UNK] , [UNK] , key distribution , and bloom filters [UNK] and bloom filters have a lot of \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:  [sos] [UNK] [UNK] , [UNK] , key distribution , and bloom filters [UNK] and bloom filters have a lot of /b&gt it /b&gt t say they would end an american league in fact that will try to make more countries [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  8\n",
      "text_input:  [sos] e-mail scam targets police chief [UNK] police warns about phishing after its fraud squad chief was targeted . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] e-mail scam targets police chief [UNK] police warns about phishing after its fraud squad chief was targeted . [eos] \n",
      "\n",
      "s:  [sos] e-mail scam targets police chief [UNK] police warns about phishing after its fraud squad chief was targeted . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  9\n",
      "text_input:  [sos] card fraud unit nets 36 , 000 cards in its first two years , the uk ' s dedicated card fraud unit , has recovered 36 , 000 stolen cards and 171 arrests - and estimates it saved 65m . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] card fraud unit nets 36 , 000 cards in its first two years , the uk ' s dedicated \n",
      "\n",
      "s:  [sos] card fraud unit nets 36 , 000 cards in its first two years , the uk ' s dedicated to cut of its stake in which they would not have to have to make /b&gt the other countries were [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  10\n",
      "text_input:  [sos] group to propose new high-speed wireless format los angeles ( reuters ) - a group of technology companies including texas instruments inc . &lt txn . n&gt , stmicroelectronics &lt stm . [UNK] and broadcom corp . &lt brcm . o&gt , on thursday said they will propose a new wireless networking standard up to 10 times the speed of the current generation . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] group to propose new high-speed wireless format los angeles ( reuters ) - a group of technology companies including \n",
      "\n",
      "s:  [sos] group to propose new high-speed wireless format los angeles ( reuters ) - a group of technology companies including three of /b&gt two dozen they would have to begin selling its five days , the european which have to [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  11\n",
      "text_input:  [sos] apple launches graphics software , video bundle los angeles ( reuters ) - apple computer inc . &lt aapl . o&gt on tuesday began shipping a new program designed to let users create real-time motion graphics and unveiled a discount video-editing software bundle featuring its flagship final cut pro software . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] apple launches graphics software , video bundle los angeles ( reuters ) - apple computer inc . &lt aapl \n",
      "\n",
      "s:  [sos] apple launches graphics software , video bundle los angeles ( reuters ) - apple computer inc . &lt aapl . 5 , including five days to boost to make /b&gt in addition to play in place in place in [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  12\n",
      "text_input:  [sos] dutch retailer beats apple to local download market amsterdam ( reuters ) - free record shop , a dutch music retail chain , beat apple computer inc . to market on tuesday with the launch of a new download service in europe ' s latest battleground for digital song services . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] dutch retailer beats apple to local download market amsterdam ( reuters ) - free record shop , a dutch \n",
      "\n",
      "s:  [sos] dutch retailer beats apple to local download market amsterdam ( reuters ) - free record shop , a dutch league in january , which have signed an end of the european union in addition to be worth of two [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  13\n",
      "text_input:  [sos] super ant colony hits australia a giant 100km colony of ants which has been discovered in melbourne , australia , could threaten local insect species . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] super ant colony hits australia a giant 100km colony of ants which has been discovered in melbourne , australia \n",
      "\n",
      "s:  [sos] super ant colony hits australia a giant 100km colony of ants which has been discovered in melbourne , australia not to an agreement to #36 6 billion in the next 12 , they have be worth more to the [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  14\n",
      "text_input:  [sos] [UNK] unite dolphin groups dolphin groups , or pods , rely on [UNK] to keep them from collapsing , scientists claim . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] [UNK] unite dolphin groups dolphin groups , or pods , rely on [UNK] to keep them from collapsing , \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:  [sos] [UNK] unite dolphin groups dolphin groups , or pods , rely on [UNK] to keep them from collapsing , which he to make its may have reached an american league in cash in january , which have to which [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "j:  15\n",
      "text_input:  [sos] teenage t . rex ' s monster growth tyrannosaurus rex achieved its massive size due to an enormous growth spurt during its adolescent years . [eos] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] \n",
      "\n",
      "text_input cut off:  [sos] teenage t . rex ' s monster growth tyrannosaurus rex achieved its massive size due to an enormous growth \n",
      "\n",
      "s:  [sos] teenage t . rex ' s monster growth tyrannosaurus rex achieved its massive size due to an enormous growth in which to two countries have made an end of they will not to be worth to have to win [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "### load first couple of test strings\n",
    "\n",
    "for i, (x, y, paddings) in enumerate(testloader):\n",
    "    \n",
    "    for j, x_ in enumerate(x):\n",
    "        print(\"j: \", j)\n",
    "        complete_sentence(trained_model, x_, paddings[j], ntok=20)\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
